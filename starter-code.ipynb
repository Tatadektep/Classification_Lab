{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e043b2",
   "metadata": {},
   "source": [
    "## Week 4, Lab 1: Predicting Left-Handedness from Psychological Factors\n",
    "> Author: Matt Brems\n",
    "\n",
    "One way to define the data science process is as follows:\n",
    "\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "We'll walk through a full data science problem in this lab. \n",
    "\n",
    "---\n",
    "## Define The Problem.\n",
    "\n",
    "You're currently a data scientist working at a university. A professor of psychology is attempting to study the relationship between personalities and left-handedness. They have tasked you with gathering evidence so that they may publish.\n",
    "\n",
    "As a data scientist, you know that any real data science problem must be **specific** and **conclusively answerable**. For example:\n",
    "- Bad data science problem: \"What is the link between obesity and blood pressure?\"\n",
    "    - This is vague and is not conclusively answerable. That is, two people might look at the conclusion and one may say \"Sure, the problem has been answered!\" and the other may say \"The problem has not yet been answered.\"\n",
    "- Good data science problem: \"Does an association exist between obesity and blood pressure?\"\n",
    "    - This is more specific and is conclusively answerable. The problem specifically is asking for a \"Yes\" or \"No\" answer. Based on that, two independent people should both be able to say either \"Yes, the problem has been answered\" or \"No, the problem has not yet been answered.\"\n",
    "- Excellent data science problem: \"As obesity increases, how does blood pressure change?\"\n",
    "    - This is very specific and is conclusively answerable. The problem specifically seeks to understand the effect of one variable on the other.\n",
    "\n",
    "### In the context of the left-handedness and personality example, what are three specific and conclusively answerable problems that you could answer using data science? \n",
    "\n",
    "> You might find it helpful to check out the codebook in the repo for some inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dda8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32144652",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### Read in the file titled \"data.csv\":\n",
    "> Hint: Despite being saved as a .csv file, you won't be able to simply `pd.read_csv()` this data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a154e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e730059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50b55b21",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### Conduct background research:\n",
    "\n",
    "Domain knowledge is irreplaceable. Figuring out what information is relevant to a problem, or what data would be useful to gather, is a major part of any end-to-end data science project! For this lab, you'll be using a dataset that someone else has put together, rather than collecting the data yourself.\n",
    "\n",
    "Do some background research about personality and handedness. What features, if any, are likely to help you make good predictions? How well do you think you'll be able to model this? Write a few bullet points summarizing what you believe, and remember to cite external sources.\n",
    "\n",
    "You don't have to be exhaustive here. Do enough research to form an opinion, and then move on.\n",
    "\n",
    "> You'll be using the answers to Q1-Q44 for modeling; you can disregard other features, e.g. country, age, internet browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5eff1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3adf0649",
   "metadata": {},
   "source": [
    "### Conduct exploratory data analysis on this dataset:\n",
    "\n",
    "If you haven't already, be sure to check out the codebook in the repo, as that will help in your EDA process.\n",
    "\n",
    "You might use this section to perform data cleaning if you find it to be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfaf7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb26e657",
   "metadata": {},
   "source": [
    "### Calculate and interpret the baseline accuracy rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ecc3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2016bb4e",
   "metadata": {},
   "source": [
    "### Short answer questions:\n",
    "\n",
    "In this lab you'll use K-nearest neighbors and logistic regression to model handedness based off of psychological factors. Answer the following related questions; your answers may be in bullet points.\n",
    "\n",
    "#### Describe the difference between regression and classification problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4807bf69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7469aee",
   "metadata": {},
   "source": [
    "#### Considering $k$-nearest neighbors, describe the relationship between $k$ and the bias-variance tradeoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a758c2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bdc66d6",
   "metadata": {},
   "source": [
    "#### Why do we often standardize predictor variables when using $k$-nearest neighbors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a175b54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ad52536",
   "metadata": {},
   "source": [
    "#### Do you think we should standardize the explanatory variables for this problem? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ccc6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cf6e09f",
   "metadata": {},
   "source": [
    "#### How do we settle on $k$ for a $k$-nearest neighbors model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8aa87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "958fe4a8",
   "metadata": {},
   "source": [
    "#### What is the default type of regularization for logistic regression as implemented in scikit-learn? (You might [check the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49dadcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4b117e3",
   "metadata": {},
   "source": [
    "#### Describe the relationship between the scikit-learn `LogisticRegression` argument `C` and regularization strength:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bece7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f19a574",
   "metadata": {},
   "source": [
    "#### Describe the relationship between regularization strength and the bias-variance tradeoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c2edec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7089674d",
   "metadata": {},
   "source": [
    "#### Logistic regression is considered more interpretable than $k$-nearest neighbors. Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf94e95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00360fc0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4 & 5 Modeling: $k$-nearest neighbors\n",
    "\n",
    "### Train-test split your data:\n",
    "\n",
    "Your explanatory variables should be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7239cca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "772f7e27",
   "metadata": {},
   "source": [
    "#### Create and fit four separate $k$-nearest neighbors models: one with $k = 3$, one with $k = 5$, one with $k = 15$, and one with $k = 25$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa73e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ea6f202",
   "metadata": {},
   "source": [
    "### Evaluate your models:\n",
    "\n",
    "Evaluate each of your four models on the training and testing sets, and interpret the four scores. Are any of your models overfit or underfit? Do any of your models beat the baseline accuracy rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41192bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2426665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de73199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8488dc25",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4 & 5 Modeling: logistic regression\n",
    "\n",
    "#### Create and fit four separate logistic regression models: one with LASSO and $\\alpha = 1$, one with LASSO and $\\alpha = 10$, one with Ridge and $\\alpha = 1$, and one with Ridge and $\\alpha = 10$. *(Hint: Be careful with how you specify $\\alpha$ in your model!)*\n",
    "\n",
    "Note: You can use the same train and test data as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96a2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "703eecea",
   "metadata": {},
   "source": [
    "### Evaluate your models:\n",
    "\n",
    "Evaluate each of your four models on the training and testing sets, and interpret the four scores. Are any of your models overfit or underfit? Do any of your models beat the baseline accuracy rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c9ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e36a746e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "Are any of your models worth moving forward with? What are the \"best\" models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeac9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
